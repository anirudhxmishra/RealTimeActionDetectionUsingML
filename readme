
# ğŸ¥ **Action Recognition Using LSTM**  

A real-time action recognition system leveraging **LSTM-based neural networks** to classify **10 distinct actions**. Powered by **Mediapipe Holistic** for robust keypoint detection and designed with scalability in mind, this project is ready for future enhancements.  

---

## âœ¨ **Features**  
- **ğŸ”Ÿ Action Recognition:** Classifies 10 unique actions in the initial implementation.  
- **âš¡ Real-Time Predictions:** Supports both live and recorded inputs for instant recognition.  
- **ğŸ› ï¸ Customizable Dataset:** Easily extendable to include new actions.  
- **ğŸ§  LSTM Model:** Optimized for sequential time-series data such as human motion keypoints.  
- **ğŸ¯ Robust Input Processing:** Utilizes Mediapipe Holistic for consistent feature extraction.  

---

## ğŸ“‚ **Dataset Structure**  

The dataset consists of `.npy` files containing Mediapipe Holistic keypoints for each action. Add new actions by following this simple structure:  

```plaintext
dataset/  
â”œâ”€â”€ action_1/  
â”‚   â”œâ”€â”€ file1.npy  
â”‚   â”œâ”€â”€ file2.npy  
â”‚   â””â”€â”€ ...  
â”œâ”€â”€ action_2/  
â”‚   â”œâ”€â”€ file1.npy  
â”‚   â”œâ”€â”€ file2.npy  
â”‚   â””â”€â”€ ...  
â””â”€â”€ ...  
```

---

## âš™ï¸ **Requirements**  
- **Python 3.7+**  
- **TensorFlow 2.0+**  
- **NumPy**  
- **Mediapipe**  
- **Matplotlib**  

Install dependencies with:  
```
pip install tensorflow numpy mediapipe matplotlib
```

---

## ğŸš€ **Usage**  

### Step 1: Dataset Preparation  
Ensure the dataset follows the proper structure and update the `DATA_PATH` variable in the notebook to point to the dataset location.  

### Step 2: Training the Model  
Train the LSTM model using the provided training cells in the notebook.  

### Step 3: Testing the Model  
Evaluate performance using the provided test sequences.  

### Step 4: Real-Time Recognition  
Test live video predictions by running the real-time recognition section in the notebook.  

---

## ğŸ—ï¸ **Model Architecture**  
The **LSTM** model is built to handle sequential data with the following layers:  
- **Input Layer:** Processes Mediapipe Holistic keypoints.  
- **LSTM Layers:** Captures temporal patterns in the data.  
- **Dense Layers:** Outputs probabilities for each action.  

---

## ğŸ“Š **Current Results**  
- **Actions Recognized:** 10  
- **Accuracy:** 96%  
- **Loss:** 0.08  

---

## ğŸŒŸ **Future Enhancements**  
- Expand the dataset to include more actions.  
- Optimize the model architecture and hyperparameters.  
- Deploy on mobile/edge devices for low-latency environments.  
- Integrate **OpenCV** for enhanced live input handling.  

---

## ğŸ¤ **Contributing**  
Contributions are welcome! ğŸš€  
Feel free to:  
1. Add new actions.  
2. Improve the code or optimize performance.  
3. Fork the repository and open a pull request.  

---

## ğŸ“œ **License**  
This project is licensed under the **MIT License**.  
